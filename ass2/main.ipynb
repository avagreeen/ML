{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervised\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:33: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'std': 0.5, 'mean': 0.5}, {'std': 0.03454868880514405, 'mean': 0.29035140288749661})\n",
      "self-training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/discriminant_analysis.py:455: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/covariance/empirical_covariance_.py:75: UserWarning: Only one sample available. You may want to reshape your data array\n",
      "  warnings.warn(\"Only one sample available. \"\n"
     ]
    }
   ],
   "source": [
    "from SSLDA_Classifier import SSLDA_Classifier\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as rnd\n",
    "import math as m\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy.stats import multivariate_normal, bernoulli\n",
    "from copy import copy\n",
    "from getData import *\n",
    "\n",
    "def errors(X,y,y_true,classifier,n=100):\n",
    "    mask = np.ones(len(y), dtype=bool)  #mask is len of labels\n",
    "    mask[np.where(y==-1)[0]]=False    #mask 1  1 1 false 1 1 is where the labeled data\n",
    "    train_error = 1 - classifier.score(X[mask,:],y[mask])  # X[mask] is the labeled data train with labeled dta\n",
    "    test_error = 1 - classifier.score(X[~mask,:],y_true[~mask])  #\n",
    "    return train_error, test_error\n",
    "\n",
    "def getLikelihood(X,y, method, Nunl, max_iter=100):\n",
    "    X_train, y_train, y_train_true, X_test, y_test = split_data(X,y,N_unlabeled=Nunl)\n",
    "    sslda=SSLDA_Classifier(max_iter)\n",
    "    sslda.fit(X_train, y_train, method=method)\n",
    "    C1 = np.where(y_train=='0')[0] #indexs of label=0\n",
    "    C2 = np.where(y_train=='1')[0]\n",
    "    \n",
    "    log_proba = sslda.predict_log_proba(X_train)\n",
    "    loglikelihood = sum(log_proba[C1,0])+ sum(log_proba[C2,0])\n",
    "    return loglikelihood\n",
    "\n",
    "def getError(X,y,method,Nunl,max_iter=100):\n",
    "    X_train, y_train, y_train_true, X_test, y_test = split_data(X,y,N_unlabeled=Nunl)\n",
    "    labelled = np.where(y_train!=-1)[0]\n",
    "    sslda = SSLDA_Classifier(max_iter)\n",
    "    sslda.fit(X_train,y_train, method=method)\n",
    "    train_err = 1-sslda.score(X_train[labelled,:], y_train_true[labelled])\n",
    "    \n",
    "    test_err = 1-sslda.score(X_test, y_test)\n",
    "    #print(train_err)\n",
    "    return train_err, test_err\n",
    "\n",
    "\n",
    "def getErrors(X,y,method,Nunl,repeat,max_iter=100):\n",
    "    #X_train, y_train, y_train_true, X_test, y_test = split_data(X,y,N_unlabeled=Nunl)\n",
    "    errors = [getError(X,y,method,Nunl,max_iter) for i in range(0,repeat)]\n",
    "    train_errors = np.array([error[0] for error in errors])\n",
    "    test_errors = np.array([error[1] for error in errors])\n",
    "    return train_errors, test_errors\n",
    "\n",
    "def plotErrors(X,y, N_unlabelled,methods, repeat, max_iter=100):\n",
    "#    methods = ['supervised', 'self-training', 'label-propagation']\n",
    "    errors = {'supervised' : [], 'self-training' : [], 'label-propagation' : []}\n",
    "    likelihoods = {'supervised' : [], 'self-training' : [], 'label-propagation' : []}\n",
    "    for method in methods:\n",
    "        print(method)\n",
    "        for Nunl in N_unlabelled:\n",
    "            train_likelihoods = getLikelihoods(X,y,method,Nunl,repeat,max_iter=max_iter)\n",
    "            '''\n",
    "            train_errors, test_errors= getErrors (X,y,method, Nunl, repeat, max_iter=max_iter)\n",
    "            train_error = train_errors.mean()\n",
    "            test_error = test_errors.mean()\n",
    "            likelihood = train_likelihoods.mean()\n",
    "            errors[method].append({'train': train_error, 'test': test_error})\n",
    "            likelihoods[method].append(likelihood)\n",
    "            '''\n",
    "            train_likelihoods = getLikelihoods(X,y,method,Nunl,repeat,max_iter=max_iter)\n",
    "            train_errors, test_errors = getErrors(X,y,method, Nunl, repeat, max_iter=max_iter)\n",
    "            train_error = {'mean' : train_errors.mean(), 'std' : train_errors.std()}\n",
    "            test_error = {'mean' : test_errors.mean(), 'std' : test_errors.std()}\n",
    "            likelihood = {'mean' : train_likelihoods.mean(), 'std' : train_likelihoods.std()}\n",
    "            errors[method].append({'train': train_error, 'test': test_error})\n",
    "            likelihoods[method].append(likelihood)\n",
    "\n",
    "        print(train_error, test_error)\n",
    "       # print(likelihood)\n",
    "        #train_means = \n",
    "            \n",
    "def getLikelihoods(X,y,method, Nunl, repeat, max_iter):\n",
    "    likelihoods = [getLikelihood(X,y,method, Nunl, max_iter=100) for i in range(0,repeat)]\n",
    "    return np.array(likelihoods)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "N_unlabelled = [0, 10, 20, 40, 80, 160, 320, 640]\n",
    "methods = ['supervised', 'self-training', 'label-propagation']\n",
    "repeat = 10\n",
    "max_iter=100\n",
    "\n",
    "\n",
    "X,y=load_magic()\n",
    "#X_train, y_train, y_train_true, X_test, y_test = split_data(X,y,N_unlabeled=20)\n",
    "\n",
    "\n",
    "plotErrors(X,y, N_unlabelled,methods, repeat, max_iter)\n",
    "    \n",
    "    \n",
    "    \n",
    "#yy=getLikelihood(X_train, y_train,method, Nnul,max_iter , p)\n",
    "\n",
    "#getLikelihoods(X_train, y_train,method, Nnul, repeat,max_iter , p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
