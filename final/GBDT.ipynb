{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "from sklearn import linear_model  \n",
    "from sklearn.preprocessing import OneHotEncoder  \n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "%matplotlib inline\n",
    "from sklearn import svm\n",
    "from my_models import *\n",
    "from sklearn.decomposition import PCA\n",
    "#from SSLDA_Classifier import SSLDA_Classifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 204)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "data=[]\n",
    "with open('train.csv') as f:\n",
    "    reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "    for row in reader:\n",
    "        data.append(row)\n",
    "np_data=np.array(data)\n",
    "label= np_data[:,0]\n",
    "trn_feature = np_data[:,1:]\n",
    "trn_feature.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 204)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=[]\n",
    "with open('test.csv') as f:\n",
    "    reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "    for row in reader:\n",
    "        data.append(row)\n",
    "np_data=np.array(data)\n",
    "\n",
    "tst_feature = np_data\n",
    "tst_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(X):\n",
    "    mean_X=X.mean(axis=0)\n",
    "    X=X-mean_X\n",
    "    X2=np.square(X)\n",
    "    var=X2.mean(axis=0)\n",
    "    sd=np.sqrt(var)\n",
    "    X=X/sd\n",
    "    return X\n",
    "trn=norm(trn_feature)\n",
    "tst=norm(tst_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=label-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Try kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from scipy import stats\n",
    "kmodel = KMeans(n_clusters=2, random_state=9).fit(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = kmodel.predict(trn)\n",
    "cluster=[]\n",
    "c_label=[]\n",
    "cluster_label=[]\n",
    "for ctype in set(y_pred):\n",
    "    idx = np.where(y_pred==ctype)\n",
    "   # cluster_center = X[idx].mean(axis=0);\n",
    "    label=Y[idx]\n",
    "    #print label,stats.mode(label)[0][0]\n",
    "    cluster_label.append(stats.mode(label)[0][0])\n",
    "    #cluster.append(cluster_center)\n",
    "    c_label.append(label)\n",
    "CX=np.array(cluster)\n",
    "CY=np.array(cluster_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(200-sum(abs(y_pred-Y)))/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmodel = KMeans(n_clusters=2, random_state=9).fit(trn)\n",
    "y_pred = kmodel.predict(trn)\n",
    "cluster=[]\n",
    "c_label=[]\n",
    "cluster_label=[]\n",
    "for ctype in set(y_pred):\n",
    "    idx = np.where(y_pred==ctype)\n",
    "   # cluster_center = X[idx].mean(axis=0);\n",
    "    label=Y[idx]\n",
    "    #print label,stats.mode(label)[0][0]\n",
    "    cluster_label.append(stats.mode(label)[0][0])\n",
    "    #cluster.append(cluster_center)\n",
    "    c_label.append(label)\n",
    "CX=np.array(cluster)\n",
    "CY=np.array(cluster_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(200-sum(abs(y_pred-Y)))/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata=np.concatenate([trn,tst])\n",
    "var=[]\n",
    "errs=[]\n",
    "for i in range(1,200):\n",
    "    pca = PCA(n_components=i)\n",
    "\n",
    "    pca.fit(pdata)\n",
    "    P=pca.transform(pdata)\n",
    "    \n",
    "    var.append(sum(pca.explained_variance_ratio_))\n",
    "    \n",
    "    Ptrn=P[:len(trn),:]\n",
    "    Ptst=P[len(trn):,:]\n",
    "\n",
    "    kmodel = KMeans(n_clusters=2, random_state=9).fit(Ptst)\n",
    "    y_pred = kmodel.predict(Ptrn)\n",
    "    cluster=[]\n",
    "    c_label=[]\n",
    "    cluster_label=[]\n",
    "    for ctype in set(y_pred):\n",
    "        idx = np.where(y_pred==ctype)\n",
    "        #cluster_center = X[idx].mean(axis=0);\n",
    "        label=Y[idx]\n",
    "        cluster_label.append(stats.mode(label)[0][0])\n",
    "        #cluster.append(cluster_center)\n",
    "        c_label.append(label)\n",
    "    CX=np.array(cluster)\n",
    "    CY=np.array(cluster_label)\n",
    "    \n",
    "    err=(200-sum(abs(y_pred-Y)))/200\n",
    "    \n",
    "    errs.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_err=1-np.array(errs)\n",
    "Er=np.vstack([res_err,np.array(errs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_err = np.min(Er,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(min_err)\n",
    "plt.xlabel('num of components')\n",
    "plt.ylabel('error')\n",
    "plt.savefig('kmeans_pca_error.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA after normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=normalize_feature(data)\n",
    "pca.fit(data)\n",
    "PX=pca.transform(data)\n",
    "trn_X=PX[:len(trn_feature),:]\n",
    "tst_X=PX[len(trn_feature):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(pca.explained_variance_ratio_))\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from scipy import stats\n",
    "y_pred = KMeans(n_clusters=200, random_state=9).fit_predict(PX)\n",
    "\n",
    "cluster=[]\n",
    "c_label=[]\n",
    "cluster_label=[]\n",
    "for ctype in set(y_pred):\n",
    "    idx = np.where(y_pred==ctype)\n",
    "    cluster_center = X[idx].mean(axis=0);\n",
    "    label=Y[idx]\n",
    "    cluster_label.append(stats.mode(label)[0][0])\n",
    "    cluster.append(cluster_center)\n",
    "    c_label.append(label)\n",
    "CX=np.array(cluster)\n",
    "CY=np.array(cluster_label)\n",
    "print CX.shape\n",
    "\n",
    "print CY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "def test_model(X,Y,method='svm'):\n",
    "    kf.get_n_splits(X)\n",
    "    error=[]\n",
    "    if method=='svm':\n",
    "        model = svm.NuSVC(kernel='sigmoid')\n",
    "    if method=='lda':\n",
    "        model=LinearDiscriminantAnalysis(solver='svd',store_covariance=True, n_components=10)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        train_X, test_X = X[train_index], X[test_index]\n",
    "        train_Y, test_Y = Y[train_index], Y[test_index]\n",
    "        \n",
    "        my_clf = model.fit(train_X,train_Y)\n",
    "        pre = my_clf.predict(test_X)\n",
    "     \n",
    "        err = sum(abs(pre-test_Y))/len(test_Y)\n",
    "        error.append(err)\n",
    "    print np.array(error).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(X,Y,'lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_X=pca.inverse_transform(PX)\n",
    "print restore_X.shape\n",
    "residual = X-restore_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_mean = residual.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "#res_mean.argmax()\n",
    "max_res  = heapq.nlargest(40, range(len(res_mean)), res_mean.take)\n",
    "#RX = X[:,-np.array(max_res)]\n",
    "RX = np.delete(X, max_res,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selftraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./semisup-learn')\n",
    "from frameworks.SelfLearning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "any_scikitlearn_classifier = svm.SVC(probability=True)\n",
    "lda=LinearDiscriminantAnalysis(solver='svd',store_covariance=True, n_components=10)\n",
    "\n",
    "lr=LogisticRegression()\n",
    "ssmodel = SelfLearningModel(lda)\n",
    "\n",
    "#ssmodel.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.762323862174\n",
      "(200, 150)\n"
     ]
    }
   ],
   "source": [
    "pdata=np.concatenate([trn,tst])\n",
    "var=[]\n",
    "errs=[]\n",
    "\n",
    "pca = PCA(n_components=150)\n",
    "\n",
    "pca.fit(pdata)\n",
    "P=pca.transform(pdata)\n",
    "    \n",
    "#var.append(sum(pca.explained_variance_ratio_))\n",
    "print sum(pca.explained_variance_ratio_)\n",
    "Ptrn=P[:len(trn),:]\n",
    "Ptst=P[len(trn):,:]\n",
    "print Ptrn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.75\n",
      "0.85\n",
      "0.8\n",
      "0.7\n",
      "0.75\n",
      "0.9\n",
      "0.95\n",
      "0.75\n",
      "0.85\n",
      "0.17\n"
     ]
    }
   ],
   "source": [
    "pcs_result = self_train(Ptrn,Ptst,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote = np.array(pcs_result).mean(axis=0)\n",
    "result3 = np.ones([len(tst),])\n",
    "mask3=np.where(vote>0.5)\n",
    "result3[mask3]=2\n",
    "write('pca+lda.csv',result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try denoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from scipy import stats\n",
    "kmodel = KMeans(n_clusters=500, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./sklearn-autoencoder/')\n",
    "from autoencoder import DenoisingAutoencoder\n",
    "da = DenoisingAutoencoder(n_hidden=10)\n",
    "Adata=np.concatenate([trn,tst])\n",
    "da.fit(Adata)\n",
    "new_X = da.transform(Adata)\n",
    "Atrn=new_X[:len(trn),:]\n",
    "Atst=new_X[len(trn):,:]\n",
    "lr=LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_train(Ptrn,Ptst,Y):\n",
    "    \n",
    "    kf=KFold(n_splits=10, shuffle=True)\n",
    "    kf.get_n_splits(Ptrn)\n",
    "    error=[]\n",
    "    prediction=[]\n",
    "    counter = 0\n",
    "\n",
    "    for train_index, test_index in kf.split(Ptrn):\n",
    "        counter = counter+1\n",
    "        if counter != 100:\n",
    "            train_X, test_X = Ptrn[train_index], Ptrn[test_index]\n",
    "            train_Y, test_Y = Y[train_index], Y[test_index]\n",
    "       \n",
    "\n",
    "            AX=np.concatenate([Ptst,train_X])\n",
    "            AY=np.concatenate([np.ones([len(Ptst),])*-1,train_Y])\n",
    "\n",
    "            ssmodel.fit(AX, AY)\n",
    "\n",
    "            err=ssmodel.score(test_X,test_Y)\n",
    "            error.append(1-err)\n",
    "            print err\n",
    "            \n",
    "            pred = ssmodel.predict(Ptst)\n",
    "            prediction.append(pred)\n",
    "    print np.array(error).mean()\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 204) (20000, 204)\n",
      "0.8\n",
      "0.7\n",
      "0.9\n",
      "0.85\n",
      "0.9\n",
      "0.75\n",
      "0.9\n",
      "1.0\n",
      "0.9\n",
      "0.85\n",
      "0.145\n"
     ]
    }
   ],
   "source": [
    "#use auto encoder to reconstruct the data\n",
    "#base_svm = svm.NuSVC(probability=True,kernel='sigmoid')\n",
    "#ssmodel = SelfLearningModel(base_svm)\n",
    "ssmodel = SelfLearningModel(lda)\n",
    "print Atrn.shape, Atst.shape\n",
    "auto_pre=self_train(Atrn,Atst,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramon=[]\n",
    "with open('test_labels_LDA.csv') as f:\n",
    "    reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "    for row in reader:\n",
    "        ramon.append(row)\n",
    "ref_label=np.array(ramon)\n",
    "ref=ref_label.reshape([len(ref_label),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmodel = KMeans(n_clusters=2, random_state=9).fit(tst)\n",
    "y_pred = kmodel.predict(tst)\n",
    "y_pred[np.where(y_pred==0)]=2\n",
    "print y_pred.shape\n",
    "\n",
    "sum(abs(y_pred-ref))\n",
    "sum(abs(y_pred-result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2604\n"
     ]
    }
   ],
   "source": [
    "vote = np.array(auto_pre).mean(axis=0)\n",
    "result2 = np.ones([len(tst),])\n",
    "mask2=np.where(vote>0.5)\n",
    "result2[mask2]=2\n",
    "# auro diff with pca denoise\n",
    "print sum(result3!=result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff with raw data\n",
    "sum(result2!=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(name,result2):\n",
    "    with open(name, 'wb') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, quoting=csv.QUOTE_MINIMAL)\n",
    "        for i in result2:\n",
    "            spamwriter.writerow([int(i)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "write('auto+lda.csv',result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "with open('auto+lda1.csv') as f:\n",
    "    reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "    for row in reader:\n",
    "        data.append(row)\n",
    "np_data=np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref=np_data.reshape([len(tst),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "889"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(result2!=ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write('kmeans+lda.csv',y_pred)\n",
    "write('raw+lda.csv',result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
